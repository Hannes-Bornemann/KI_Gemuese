{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contour number</th>\n",
       "      <th>aspect ratio</th>\n",
       "      <th>extent</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>Hue</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.850735</td>\n",
       "      <td>0.762296</td>\n",
       "      <td>83.383101</td>\n",
       "      <td>143.296144</td>\n",
       "      <td>143.572600</td>\n",
       "      <td>38.485644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0.626242</td>\n",
       "      <td>0.763346</td>\n",
       "      <td>76.382386</td>\n",
       "      <td>75.957386</td>\n",
       "      <td>85.665909</td>\n",
       "      <td>150.730682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>0.628238</td>\n",
       "      <td>0.695970</td>\n",
       "      <td>60.357078</td>\n",
       "      <td>114.183692</td>\n",
       "      <td>136.153077</td>\n",
       "      <td>15.567445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.896541</td>\n",
       "      <td>0.800835</td>\n",
       "      <td>44.570000</td>\n",
       "      <td>117.787500</td>\n",
       "      <td>134.971667</td>\n",
       "      <td>17.529167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>0.693736</td>\n",
       "      <td>0.824233</td>\n",
       "      <td>36.742411</td>\n",
       "      <td>117.234172</td>\n",
       "      <td>135.391154</td>\n",
       "      <td>17.088465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.808913</td>\n",
       "      <td>46.546503</td>\n",
       "      <td>110.883922</td>\n",
       "      <td>126.844989</td>\n",
       "      <td>18.361932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>0.836557</td>\n",
       "      <td>63.621205</td>\n",
       "      <td>104.295904</td>\n",
       "      <td>104.446747</td>\n",
       "      <td>29.446747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51</td>\n",
       "      <td>0.760961</td>\n",
       "      <td>0.823015</td>\n",
       "      <td>59.701164</td>\n",
       "      <td>99.514131</td>\n",
       "      <td>103.025769</td>\n",
       "      <td>32.987531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.767948</td>\n",
       "      <td>50.077372</td>\n",
       "      <td>116.466180</td>\n",
       "      <td>137.658394</td>\n",
       "      <td>22.445255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>0.828162</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>60.658955</td>\n",
       "      <td>104.919383</td>\n",
       "      <td>113.961094</td>\n",
       "      <td>34.713985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47</td>\n",
       "      <td>0.890923</td>\n",
       "      <td>0.828608</td>\n",
       "      <td>52.141768</td>\n",
       "      <td>97.165096</td>\n",
       "      <td>107.391655</td>\n",
       "      <td>28.818304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>45</td>\n",
       "      <td>0.950329</td>\n",
       "      <td>0.748096</td>\n",
       "      <td>48.570281</td>\n",
       "      <td>121.473896</td>\n",
       "      <td>109.674699</td>\n",
       "      <td>15.439759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39</td>\n",
       "      <td>0.901044</td>\n",
       "      <td>0.802361</td>\n",
       "      <td>56.255943</td>\n",
       "      <td>103.945878</td>\n",
       "      <td>107.513404</td>\n",
       "      <td>25.372281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43</td>\n",
       "      <td>0.332057</td>\n",
       "      <td>0.831787</td>\n",
       "      <td>70.409836</td>\n",
       "      <td>125.392697</td>\n",
       "      <td>123.234724</td>\n",
       "      <td>15.734724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>53</td>\n",
       "      <td>0.539305</td>\n",
       "      <td>0.713518</td>\n",
       "      <td>44.690566</td>\n",
       "      <td>132.909434</td>\n",
       "      <td>108.475472</td>\n",
       "      <td>15.988679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>47</td>\n",
       "      <td>0.915618</td>\n",
       "      <td>0.802961</td>\n",
       "      <td>51.757838</td>\n",
       "      <td>96.647207</td>\n",
       "      <td>110.642883</td>\n",
       "      <td>25.927928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44</td>\n",
       "      <td>0.895546</td>\n",
       "      <td>0.804060</td>\n",
       "      <td>49.621212</td>\n",
       "      <td>113.057576</td>\n",
       "      <td>129.633333</td>\n",
       "      <td>19.928485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>43</td>\n",
       "      <td>0.857774</td>\n",
       "      <td>0.824611</td>\n",
       "      <td>49.933726</td>\n",
       "      <td>103.039764</td>\n",
       "      <td>103.941090</td>\n",
       "      <td>24.423417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>56</td>\n",
       "      <td>0.869177</td>\n",
       "      <td>0.740080</td>\n",
       "      <td>47.124276</td>\n",
       "      <td>96.096893</td>\n",
       "      <td>106.345445</td>\n",
       "      <td>22.131648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.800512</td>\n",
       "      <td>61.808598</td>\n",
       "      <td>120.565507</td>\n",
       "      <td>133.734903</td>\n",
       "      <td>23.387922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>32</td>\n",
       "      <td>0.833056</td>\n",
       "      <td>0.759383</td>\n",
       "      <td>69.681489</td>\n",
       "      <td>130.451396</td>\n",
       "      <td>135.159772</td>\n",
       "      <td>29.740951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>37</td>\n",
       "      <td>0.829181</td>\n",
       "      <td>0.845393</td>\n",
       "      <td>66.053129</td>\n",
       "      <td>114.175146</td>\n",
       "      <td>116.579469</td>\n",
       "      <td>30.694282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30</td>\n",
       "      <td>0.485071</td>\n",
       "      <td>0.702420</td>\n",
       "      <td>49.119904</td>\n",
       "      <td>138.414868</td>\n",
       "      <td>121.925659</td>\n",
       "      <td>15.513189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32</td>\n",
       "      <td>0.980371</td>\n",
       "      <td>0.821115</td>\n",
       "      <td>51.574273</td>\n",
       "      <td>105.982644</td>\n",
       "      <td>119.282797</td>\n",
       "      <td>20.357325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21</td>\n",
       "      <td>0.295276</td>\n",
       "      <td>0.606957</td>\n",
       "      <td>45.597772</td>\n",
       "      <td>105.618812</td>\n",
       "      <td>87.506188</td>\n",
       "      <td>14.122525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>0.744034</td>\n",
       "      <td>0.733916</td>\n",
       "      <td>46.540091</td>\n",
       "      <td>125.791225</td>\n",
       "      <td>131.895613</td>\n",
       "      <td>15.107413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.890225</td>\n",
       "      <td>0.796147</td>\n",
       "      <td>59.744609</td>\n",
       "      <td>121.887466</td>\n",
       "      <td>131.185310</td>\n",
       "      <td>23.881402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>46</td>\n",
       "      <td>0.761577</td>\n",
       "      <td>0.740366</td>\n",
       "      <td>77.767327</td>\n",
       "      <td>169.185644</td>\n",
       "      <td>152.433168</td>\n",
       "      <td>18.851485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>54</td>\n",
       "      <td>0.973464</td>\n",
       "      <td>0.796973</td>\n",
       "      <td>69.041156</td>\n",
       "      <td>138.403678</td>\n",
       "      <td>134.596322</td>\n",
       "      <td>31.928196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>47</td>\n",
       "      <td>0.967616</td>\n",
       "      <td>0.795259</td>\n",
       "      <td>66.446500</td>\n",
       "      <td>138.572003</td>\n",
       "      <td>142.431215</td>\n",
       "      <td>23.319389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    contour number  aspect ratio    extent       Blue       Green         Red  \\\n",
       "0               16      0.850735  0.762296  83.383101  143.296144  143.572600   \n",
       "1               25      0.626242  0.763346  76.382386   75.957386   85.665909   \n",
       "2               31      0.628238  0.695970  60.357078  114.183692  136.153077   \n",
       "3               31      0.896541  0.800835  44.570000  117.787500  134.971667   \n",
       "4               63      0.693736  0.824233  36.742411  117.234172  135.391154   \n",
       "5               34      0.928571  0.808913  46.546503  110.883922  126.844989   \n",
       "6               68      0.979804  0.836557  63.621205  104.295904  104.446747   \n",
       "7               51      0.760961  0.823015  59.701164   99.514131  103.025769   \n",
       "8               31      0.957265  0.767948  50.077372  116.466180  137.658394   \n",
       "9               50      0.828162  0.845766  60.658955  104.919383  113.961094   \n",
       "10              47      0.890923  0.828608  52.141768   97.165096  107.391655   \n",
       "11              45      0.950329  0.748096  48.570281  121.473896  109.674699   \n",
       "12              39      0.901044  0.802361  56.255943  103.945878  107.513404   \n",
       "13              43      0.332057  0.831787  70.409836  125.392697  123.234724   \n",
       "14              53      0.539305  0.713518  44.690566  132.909434  108.475472   \n",
       "15              47      0.915618  0.802961  51.757838   96.647207  110.642883   \n",
       "16              44      0.895546  0.804060  49.621212  113.057576  129.633333   \n",
       "17              43      0.857774  0.824611  49.933726  103.039764  103.941090   \n",
       "18              56      0.869177  0.740080  47.124276   96.096893  106.345445   \n",
       "19              33      0.901961  0.800512  61.808598  120.565507  133.734903   \n",
       "20              32      0.833056  0.759383  69.681489  130.451396  135.159772   \n",
       "21              37      0.829181  0.845393  66.053129  114.175146  116.579469   \n",
       "22              30      0.485071  0.702420  49.119904  138.414868  121.925659   \n",
       "23              32      0.980371  0.821115  51.574273  105.982644  119.282797   \n",
       "24              21      0.295276  0.606957  45.597772  105.618812   87.506188   \n",
       "25              27      0.744034  0.733916  46.540091  125.791225  131.895613   \n",
       "26              26      0.890225  0.796147  59.744609  121.887466  131.185310   \n",
       "27              46      0.761577  0.740366  77.767327  169.185644  152.433168   \n",
       "28              54      0.973464  0.796973  69.041156  138.403678  134.596322   \n",
       "29              47      0.967616  0.795259  66.446500  138.572003  142.431215   \n",
       "\n",
       "           Hue  class  \n",
       "0    38.485644      0  \n",
       "1   150.730682      0  \n",
       "2    15.567445      0  \n",
       "3    17.529167      0  \n",
       "4    17.088465      0  \n",
       "5    18.361932      0  \n",
       "6    29.446747      0  \n",
       "7    32.987531      0  \n",
       "8    22.445255      0  \n",
       "9    34.713985      0  \n",
       "10   28.818304      0  \n",
       "11   15.439759      0  \n",
       "12   25.372281      0  \n",
       "13   15.734724      0  \n",
       "14   15.988679      0  \n",
       "15   25.927928      0  \n",
       "16   19.928485      0  \n",
       "17   24.423417      0  \n",
       "18   22.131648      0  \n",
       "19   23.387922      0  \n",
       "20   29.740951      0  \n",
       "21   30.694282      0  \n",
       "22   15.513189      0  \n",
       "23   20.357325      0  \n",
       "24   14.122525      0  \n",
       "25   15.107413      0  \n",
       "26   23.881402      0  \n",
       "27   18.851485      0  \n",
       "28   31.928196      0  \n",
       "29   23.319389      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [\"contour number\", \"aspect ratio\", \"extent\", \"Blue\", \"Green\", \"Red\", \"Hue\"]\n",
    "data = pd.read_csv(\"output.csv\", index_col=0)\n",
    "data_burghart = pd.read_csv(\"output_burghart.csv\", index_col=0)\n",
    "# besser als excel weil csv weniger Metadaten speichert und so bei vielen Bildern Rechenzeit reduziert wird\n",
    "# data = pd.read_excel(\"output.xlsx\", skiprows=1, header=None, names=col_names)\n",
    "data.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasse für Knoten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_index=None,\n",
    "        threshold=None,\n",
    "        left=None,\n",
    "        right=None,\n",
    "        info_gain=None,\n",
    "        value=None,\n",
    "    ):\n",
    "        \"\"\"constructor\"\"\"\n",
    "\n",
    "        # für decision node\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "\n",
    "        # für leaf node\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasse für Erstellung des Baumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        \"\"\"constructor\"\"\"\n",
    "\n",
    "        # Initialisiere root des decision tree, wird benötigt um tree zu durchlaufen\n",
    "        self.root = None\n",
    "\n",
    "        # node wird nicht weiter verästelt wenn:\n",
    "        self.min_samples_split = min_samples_split  # wenn Anzahl der Samples aus den trainingsdaten im node weniger als dieser wert wird, wird node zu leaf node\n",
    "        self.max_depth = max_depth  # wenn max anzahl an verketteten Ebenen erreicht ist, wird node zu leaf node\n",
    "\n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        \"\"\"rekursive Funktion um decision tree aufzubauen\"\"\"\n",
    "        # Array an Trainingsdaten wird aufgespalten: Merkmale X werden von Klassenzuordnung Y (letzte Spalte) getrennt\n",
    "        X, Y = dataset[:, :-1], dataset[:, -1]\n",
    "        # Abfrage: num_samples= Anzahl Zeilen der features; num_features= Anzahl Spalten der features\n",
    "        num_samples, num_features = np.shape(X)\n",
    "\n",
    "        # weiter verästeln, bis Stop-Bedingung\n",
    "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
    "            # finde beste Aufteilung (maximiere information gain)\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            # überprüfe ob information gain positiv, wenn nicht besteht Knoten nur noch aus einer Klasse\n",
    "            if best_split[\"info_gain\"] > 0:\n",
    "                # Rekursion für linke Seite des Baumes bis überall leaf nodes\n",
    "                left_subtree = self.build_tree(\n",
    "                    best_split[\"dataset_left\"], curr_depth + 1\n",
    "                )\n",
    "                # Rekursion für rechte Seite\n",
    "                right_subtree = self.build_tree(\n",
    "                    best_split[\"dataset_right\"], curr_depth + 1\n",
    "                )\n",
    "                # gebe decision node zurück\n",
    "                return Node(\n",
    "                    best_split[\"feature_index\"],\n",
    "                    best_split[\"threshold\"],\n",
    "                    left_subtree,\n",
    "                    right_subtree,\n",
    "                    best_split[\"info_gain\"],\n",
    "                )\n",
    "\n",
    "        # berechne leaf node\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        # gebe leaf node zurück\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        \"\"\"function to find the best split\"\"\"\n",
    "\n",
    "        # dictionary um beste Teilung zu speichern\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "\n",
    "        # Durch alle Merkmale iterieren\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            # iterieren durch alle Merkmalswerte im Datensatz\n",
    "            for threshold in possible_thresholds:\n",
    "                # Teilung berechnen\n",
    "                dataset_left, dataset_right = self.split(\n",
    "                    dataset, feature_index, threshold\n",
    "                )\n",
    "                # resultierende Datasets dürfen nicht 0 sein\n",
    "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
    "                    # Extrahieren der Klassen aus dem übrig gegbliebenen dataset\n",
    "                    y, left_y, right_y = (\n",
    "                        dataset[:, -1],\n",
    "                        dataset_left[:, -1],\n",
    "                        dataset_right[:, -1],\n",
    "                    )\n",
    "                    # Berechnung information gain\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    # Aktualisieren der besten Teilung wenn gain größer ist als aktuelles maximun\n",
    "                    if curr_info_gain > max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "\n",
    "        # Beste Teilung zurück geben\n",
    "        return best_split\n",
    "\n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        \"\"\"function to split the data\"\"\"\n",
    "\n",
    "        dataset_left = np.array(\n",
    "            [row for row in dataset if row[feature_index] <= threshold]\n",
    "        )\n",
    "        dataset_right = np.array(\n",
    "            [row for row in dataset if row[feature_index] > threshold]\n",
    "        )\n",
    "        return dataset_left, dataset_right\n",
    "\n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        \"\"\"function to compute information gain\"\"\"\n",
    "\n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if mode == \"gini\":\n",
    "            gain = self.gini_index(parent) - (\n",
    "                weight_l * self.gini_index(l_child)\n",
    "                + weight_r * self.gini_index(r_child)\n",
    "            )\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (\n",
    "                weight_l * self.entropy(l_child) + weight_r * self.entropy(r_child)\n",
    "            )\n",
    "        return gain\n",
    "\n",
    "    def entropy(self, y):\n",
    "        \"\"\"function to compute entropy\"\"\"\n",
    "\n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "        return entropy\n",
    "\n",
    "    def gini_index(self, y):\n",
    "        \"\"\"function to compute gini index\"\"\"\n",
    "\n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "\n",
    "    def calculate_leaf_value(self, Y):\n",
    "        \"\"\"function to compute leaf node\"\"\"\n",
    "\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "\n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        \"\"\"function to print the tree\"\"\"\n",
    "\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\n",
    "                \"X_\" + str(tree.feature_index),\n",
    "                \"<=\",\n",
    "                tree.threshold,\n",
    "                \"?\",\n",
    "                tree.info_gain,\n",
    "            )\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"function to train the tree\"\"\"\n",
    "\n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"function to predict new dataset\"\"\"\n",
    "\n",
    "        predictions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return predictions\n",
    "\n",
    "    def make_prediction(self, x, tree):\n",
    "        \"\"\"function to predict a single data point\"\"\"\n",
    "\n",
    "        if tree.value != None:\n",
    "            return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val <= tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufteilung der Daten in Trainings- und Testdaten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[\n",
    "    :, :-1\n",
    "].values  # erstes \":\" für alle Zeilen, nach dem Komma \":-1\" = \"alle Spalten bis auf die letzte\", Bildung np-Array durch \".values\"\n",
    "Y = data.iloc[:, -1].values.reshape(\n",
    "    -1, 1\n",
    ")  # nur letzte Spalte. \"reshape\" konvertiert Vektor in Spaltenvektor mit 1 Spalte. durch \"-1\" werden Zeilen automatisch berechnet\n",
    "\n",
    "###---------------------------------------------------------------------------------------------------------------------------------------\n",
    "X_burghart_test = data_burghart.iloc[\n",
    "    :, :-1\n",
    "].values \n",
    "Y_burghart_test = data_burghart.iloc[:, -1].values.reshape(\n",
    "    -1, 1\n",
    ")\n",
    "###---------------------------------------------------------------------------------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Aufteilen der Daten in Trainings-und Testdaten\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=41\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_1 <= 0.3878309609528353 ? 0.22072553375626813\n",
      " left:X_1 <= 0.2934350349753082 ? 0.026704447390357558\n",
      "  left:X_6 <= 51.897590361445786 ? 0.004220719523456401\n",
      "    left:X_4 <= 196.23 ? 0.0037945497144028888\n",
      "        left:1.0\n",
      "        right:0.0\n",
      "    right:X_0 <= 68.0 ? 0.38888888888888895\n",
      "        left:0.0\n",
      "        right:1.0\n",
      "  right:X_5 <= 126.17891373801918 ? 0.11474688814671136\n",
      "    left:X_6 <= 13.82089552238806 ? 0.07569218757624563\n",
      "        left:1.0\n",
      "        right:2.0\n",
      "    right:X_0 <= 26.0 ? 0.06362047043865232\n",
      "        left:0.0\n",
      "        right:1.0\n",
      " right:X_6 <= 13.267813267813269 ? 0.07593950187761278\n",
      "  left:X_0 <= 55.0 ? 0.04406532782473077\n",
      "    left:X_3 <= 37.44842105263158 ? 0.027996841837622133\n",
      "        left:0.0\n",
      "        right:0.0\n",
      "    right:X_6 <= 11.977777777777778 ? 0.24750096116878129\n",
      "        left:1.0\n",
      "        right:2.0\n",
      "  right:X_6 <= 25.031966643502432 ? 0.05903394309657711\n",
      "    left:X_3 <= 43.2080229226361 ? 0.030239799352830443\n",
      "        left:2.0\n",
      "        right:2.0\n",
      "    right:X_0 <= 88.0 ? 0.16729107463885662\n",
      "        left:0.0\n",
      "        right:2.0\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
    "classifier.fit(X_train, Y_train)\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.8126888217522659\n",
      "accuracy score burghart: 0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test)\n",
    "Y_burghart_pred = classifier.predict(X_burghart_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"accuracy score:\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"accuracy score burghart:\", accuracy_score(Y_burghart_test, Y_burghart_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
