{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "Autoren: Hannes Bornemann, Michelle Winkle\n",
    "\n",
    "In diesem Notebook wird gezeigt, wie Transfer Learning genutzt werden kann um Gemüse zu klassifizieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "\n",
    "# setzen der Bildgröße für InceptionV3\n",
    "IMAGE_WIDTH=224\n",
    "IMAGE_HEIGHT=224\n",
    "IMAGE_CHANNELS=3\n",
    "\n",
    "# setzen der Bildanzahl, nach der das Modell die Gewichte anpasst\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfade zu den Ordnern\n",
    "folder_potato = 'photos_reduced/Kartoffel_reduced'\n",
    "folder_onion = 'photos_reduced/Zwiebel_reduced'\n",
    "folder_carrot = 'photos_reduced/Karotte_reduced'\n",
    "\n",
    "# Initialisierung der Listen\n",
    "categories = []\n",
    "filenames = []\n",
    "\n",
    "# Durchlaufen des Kartoffel-Ordners\n",
    "for filename in os.listdir(folder_potato):\n",
    "    categories.append(0)  # Kartoffel-Kategorie\n",
    "    filenames.append(os.path.join(folder_potato, filename))\n",
    "\n",
    "# Durchlaufen des Zwiebel-Ordners\n",
    "for filename in os.listdir(folder_onion):\n",
    "    categories.append(1)  # Zwiebel-Kategorie\n",
    "    filenames.append(os.path.join(folder_onion, filename))\n",
    "\n",
    "# Durchlaufen des Karotte-Ordners\n",
    "for filename in os.listdir(folder_carrot):\n",
    "    categories.append(2)  # Karotte-Kategorie\n",
    "    filenames.append(os.path.join(folder_carrot, filename))\n",
    "\n",
    "# Erstellung des DataFrames\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "\n",
    "# Ersetzen der Integer Werte für die Klasse durch strings \n",
    "df[\"category\"] = df[\"category\"].replace({0: 'potato', 1: 'onion', 2: 'carrot'}) \n",
    "\n",
    "# Teilen der Daten in Traingsdaten und Validierungsdaten\n",
    "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "\n",
    "train_number = len(train_df)\n",
    "validate_number = len(validate_df)\n",
    "print ('Anzahl der Bilder (Train):',train_number)\n",
    "print ('Anzahl der Bilder (Validate):',validate_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden wird das Modell erstellt, wobei das Netz zur Feature Extraction (Kodierungsblock) vom Inception_V3 Modell übernommen wird. Dieser muss nicht trainiert werden, was enormen Rechenaufwand spart. Der nachgelagerte Prädikationsblock nutzt die Merkmale für die Vorhersage der Klasse. Dieser muss trainiert werden und enthält eine an die spezifische Aufgabe angepasste Ausgabeschicht mit 3 Neuronen für die 3 möglichen Klassen und der softmax-Aktivierungsfunktion (da zb. mehr Klassen als 2 zu unterscheiden gibt, dazu könnte \"binary\" genutzt werden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Erstellung eines leeren sequentielles Modells\n",
    "model = models.Sequential()\n",
    "# Kodierungsblock (Featature Extractor) von InceptionV3 übernehmen (Prädikationsblock auslassen mit include_top=False)\n",
    "# Input Shape benötigt Größe 224x224x3, Testdaten werden später dirch den ImageDataGenerator darauf angepasst\n",
    "base_model = InceptionV3(weights='imagenet',include_top=False, input_shape=(224, 224, 3))\n",
    "# Hinzufügen des InceptionV3 Netzes zum Modell \n",
    "model.add(base_model)\n",
    "\n",
    "### definieren des Prädikationsblocks ####\n",
    "# Flatten Layer um die 3D Ausgabe in 1D umzuwandeln\n",
    "model.add(layers.Flatten())\n",
    "# voll verknüpfte Schichten mit 256 bzw. 512 Neuronen und ReLU Aktivierungsfunktion\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "# letzte Schicht mit 3 Neuronen und Aktivierungsfunktion für Multiklassen Klassifikation (Softmax) \n",
    "model.add(layers.Dense(3, activation='softmax')) # 3 Klassen: Zwiebel, Karotte, Kartoffel\n",
    "# deaktivieren des Training des Basis Modells \n",
    "base_model.trainable = False \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(1e-4),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorbereiten der Daten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# rescalen der Trainingsdaten von 255 auf 1 und Data Augmentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range = 0.2, \n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    "    )\n",
    "\n",
    "# rescalen der Testdaten von 255 auf 1\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    "    )\n",
    "\n",
    "# laden der Bilder über den ImageDataGenerator, dabei Anpassung der Bildgröße auf 224x224\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(IMAGE_WIDTH,IMAGE_HEIGHT),\n",
    "    batch_size  = batch_size,\n",
    "    class_mode = 'categorical' \n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    validate_df,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(IMAGE_WIDTH,IMAGE_HEIGHT),\n",
    "    batch_size  = batch_size,\n",
    "    class_mode = 'categorical' \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainieren des Netzes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "steps_per_epoch=100,\n",
    "epochs = 10,\n",
    "validation_data = test_generator,\n",
    "validation_steps=validate_number//batch_size)\n",
    "# validate_number = Gesamtanzahl der für Validierung genutzten Bilder\n",
    "# batch_size = Anzahl der Bilder, die pro \"step\" durch das Modell laufen\n",
    "# epochs =  hier werden mehrere \"steps\" durchlaufen\n",
    "#           bilder pro epoche = batch_size * steps_per_epoch\n",
    "# validation_steps = Anzahl der Schritte bis Gewichte angepasst werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Modell kann zum Vergleichen von unterschiedlichen Parametern des Prädikationsblocks abgespeichert werden\n",
    "# model.save('cats_dogs_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auswerten des Netzes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs,acc,'bo',label='Trainingsgenauigkeit')\n",
    "plt.plot(epochs,val_acc,'b',label='Validierungsgenauigkeit')\n",
    "plt.title('Trainings und  Validierungsgenauigkeit')\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs,loss,'bo',label='Trainings-Loss')\n",
    "plt.plot(epochs,val_loss,'b',label='Validierungs-Loss')\n",
    "plt.title('Trainings und  Validierungs-Loss')\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d580cc932caa59f6d64cbc09e4ecd47933d1d2aa96199041cf694e848b778d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
